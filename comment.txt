Привет, через airflow так и не удалось запутить вот лог: 
*** Reading local file: /lessons/logs/dag_id=recommend_dm/run_id=scheduled__2022-12-19T00:00:00+00:00/task_id=user_city/attempt=2.log
[2022-12-20, 20:15:51 UTC] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: recommend_dm.user_city scheduled__2022-12-19T00:00:00+00:00 [queued]>
[2022-12-20, 20:15:51 UTC] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: recommend_dm.user_city scheduled__2022-12-19T00:00:00+00:00 [queued]>
[2022-12-20, 20:15:51 UTC] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-12-20, 20:15:51 UTC] {taskinstance.py:1363} INFO - Starting attempt 2 of 2
[2022-12-20, 20:15:51 UTC] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-12-20, 20:15:51 UTC] {taskinstance.py:1383} INFO - Executing <Task(SparkSubmitOperator): user_city> on 2022-12-19 00:00:00+00:00
[2022-12-20, 20:15:51 UTC] {standard_task_runner.py:54} INFO - Started process 17821 to run task
[2022-12-20, 20:15:51 UTC] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'recommend_dm', 'user_city', 'scheduled__2022-12-19T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpcun0vqhg']
[2022-12-20, 20:15:51 UTC] {standard_task_runner.py:83} INFO - Job 6: Subtask user_city
[2022-12-20, 20:15:51 UTC] {dagbag.py:525} INFO - Filling up the DagBag from /lessons/dags/dag.py
[2022-12-20, 20:15:51 UTC] {logging_mixin.py:117} WARNING - /usr/local/lib/python3.8/dist-packages/airflow/models/dag.py:3393 RemovedInAirflow3Warning: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead.
[2022-12-20, 20:15:51 UTC] {task_command.py:384} INFO - Running <TaskInstance: recommend_dm.user_city scheduled__2022-12-19T00:00:00+00:00 [running]> on host fhmuabqh8o32e7q023b7.auto.internal
[2022-12-20, 20:15:51 UTC] {taskinstance.py:1590} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=recommend_dm
AIRFLOW_CTX_TASK_ID=user_city
AIRFLOW_CTX_EXECUTION_DATE=2022-12-19T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-12-19T00:00:00+00:00
[2022-12-20, 20:15:51 UTC] {spark_submit.py:203} INFO - Could not load connection string spark_default, defaulting to yarn
[2022-12-20, 20:15:51 UTC] {spark_submit.py:334} INFO - Spark-Submit cmd: spark-submit --master yarn --name arrow-spark scripts/user_city.py 2022-12-19 30 /user/ivichick/analytics /user/ivichick/data/silver/dim_geo /user/ivichick/data/silver/events
[2022-12-20, 20:15:52 UTC] {spark_submit.py:485} INFO - SLF4J: Class path contains multiple SLF4J bindings.
[2022-12-20, 20:15:52 UTC] {spark_submit.py:485} INFO - SLF4J: Found binding in [jar:file:/usr/lib/spark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2022-12-20, 20:15:52 UTC] {spark_submit.py:485} INFO - SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2022-12-20, 20:15:52 UTC] {spark_submit.py:485} INFO - SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[2022-12-20, 20:15:52 UTC] {spark_submit.py:485} INFO - SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[2022-12-20, 20:15:52 UTC] {spark_submit.py:485} INFO - 2022-12-20, 20:15:52 UTC WARN util.Utils: Your hostname, fhmuabqh8o32e7q023b7 resolves to a loopback address: 127.0.1.1; using 172.16.0.41 instead (on interface eth0)
[2022-12-20, 20:15:52 UTC] {spark_submit.py:485} INFO - 2022-12-20, 20:15:52 UTC WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2022-12-20, 20:15:53 UTC] {spark_submit.py:485} INFO - /usr/bin/python3: can't open file '/opt/airflow/scripts/user_city.py': [Errno 2] No such file or directory
[2022-12-20, 20:15:53 UTC] {spark_submit.py:485} INFO - 2022-12-20, 20:15:53 UTC INFO util.ShutdownHookManager: Shutdown hook called
[2022-12-20, 20:15:53 UTC] {spark_submit.py:485} INFO - 2022-12-20, 20:15:53 UTC INFO util.ShutdownHookManager: Deleting directory /tmp/spark-4eb86669-2c14-4849-82a6-b84fb7886a59
[2022-12-20, 20:15:53 UTC] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 157, in execute
    self._hook.submit(self._application)
  File "/usr/local/lib/python3.8/dist-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 416, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master yarn --name arrow-spark scripts/user_city.py 2022-12-19 30 /user/ivichick/analytics /user/ivichick/data/silver/dim_geo /user/ivichick/data/silver/events. Error code is: 2.
[2022-12-20, 20:15:53 UTC] {taskinstance.py:1401} INFO - Marking task as FAILED. dag_id=recommend_dm, task_id=user_city, execution_date=20221219T000000, start_date=20221220T201551, end_date=20221220T201553
[2022-12-20, 20:15:53 UTC] {standard_task_runner.py:102} ERROR - Failed to execute job 6 for task user_city (Cannot execute: spark-submit --master yarn --name arrow-spark scripts/user_city.py 2022-12-19 30 /user/ivichick/analytics /user/ivichick/data/silver/dim_geo /user/ivichick/data/silver/events. Error code is: 2.; 17821)
[2022-12-20, 20:15:53 UTC] {local_task_job.py:164} INFO - Task exited with return code 1
[2022-12-20, 20:15:53 UTC] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check


Такая же ошибка была и на хакатоне, не знаю как она решилась.
Возможно установка пакета, так же менял коннекшены для того что бы спарк запустился с нужным мастером не помогает.
По каждой витрине код проверля в юпитере, они собираются

Это проблема и проблема запуска приложений в юптере с мастером ярном очень сильный стопер
(логи выдают, что ярн запрашивает ресурсы, а потом падает, либо сначала вре работает, но потом валится с ошибкой по памяти,
что очень странно, объем источников, которые надо отработать не такой большой, то вообще не понятно откуда возникате очень большое кол-во тасков(порядка 40000))
, которая влияет на время сдачи задания 

Вот пример команды !hdfs dfs -du -h /user/ivichick/data/silver/
После моего репартишна, то есть данные за полгода, которые есть, это 500mb
1.3 K    1.3 K    /user/ivichick/data/silver/dim_geo
470.1 M  470.1 M  /user/ivichick/data/silver/events


На счет ошибки в airflow понял. Просто ведать тогда глаза замылились и не увидел очевидной проблемы.
На счет spark ui, когда только писал проект сервис не работал, сейчас работает, так что да можно теперь мониторить свою задачу) 

Попытался исправить все твои замечания. Спасибо за ссылки и наставления на правильный путь к решению задач!)